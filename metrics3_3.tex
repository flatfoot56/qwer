\documentclass[a4paper]{article}
\usepackage[14pt]{extsizes} % 
\usepackage[utf8]{inputenc}
\usepackage{setspace,amsmath}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{titlesec}
\usepackage{pdfpages}
\usepackage[shortlabels]{enumitem}
\usepackage{tikz}
\usetikzlibrary{angles,quotes}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{float}
\usepackage[section]{placeins}
\usepackage[makeroom]{cancel}
\usepackage{mathrsfs} % 
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%\addto\captionsrussian{\renewcommand{\figurename}{Fig.}}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} 
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
{\hbox{$\mathsurround=0pt #1$}}{}}
\usepackage{graphicx}  % 
\graphicspath{{images/}{images2/}}  % 
\setlength\fboxsep{3pt} %  \fbox{} 
\setlength\fboxrule{1pt} % \fbox{}
\usepackage{wrapfig} % 
\newcommand{\prob}{\mathbb{P}}
\newcommand{\norma}{\mathscr{N}}
\newcommand{\expect}{\mathbb{E}}
\newcommand{\summa}{\sum_{i=1}^n}
\newcommand{\yrseduc}{\textit{yrseduc}}
\usepackage[left=7mm, top=20mm, right=15mm, bottom=20mm, nohead, footskip=10mm]{geometry} % 
\usepackage{tikz} % 
\def\myrad{2cm}% radius of the circle
\def\myanga{45}% angle for the arc
\def\myangb{195}
\begin{document} % 
	\begin{flushright}
	\begin{tabular}{r}
		Danil Fedchenko, MAE 2020, group A \\
	\end{tabular}
\end{flushright}


\begin{center}
	Econometrics 2. Problem Set 3.
\end{center}
\section*{Problem 1}
In Example 12.8, we found evidence of heteroskedasticity in $u_t$ in equation (12.47). Thus, we compute the heteroskedasticity-robust standard errors along with the usual standard errors. What does using the heteroskedasticity-robust $t$ statistic do to the significance of $return_{t-1}$?

\textbf{Solution}

\begin{align*}
t_{old} = \frac{0.059}{0.038} = 1.55\\
t_{new} = \frac{0.059}{0.069} = 0.85
\end{align*}
Significance of $return_{t-1}$ becomes smaller because for non-robust case p-value is $0.06$ while in robust case it is $0.19$ i.e. for example at the significant level of 10\% non-robust t-test reject hypothesis that $return_{t-1}$ does not affect $return_t$ while robust test does not.


\section*{Problem 2}
\begin{align*}
\hat{\nu} = \sum_{t=1}^n \hat{a}_t^2 + 2 \sum_{h=1}^g \frac{g+1-h}{g+1} \left(\sum_{t = h+1}^n \hat{a}_{t}\hat{a}_{t-h}\right)
\end{align*}
To prove that $\hat{\nu} \ge 0$ firstly let us fixed some $0<g<n$. Denote 
\begin{align*}
\mu_h = \sum_{t = h+1}^n\hat{a}_t \hat{a}_{t-h}
\end{align*}
This implies
\begin{align*}
\hat{\nu} = \mu_0 + 2\sum_{h=1}^g \frac{g+1-h}{g+1}\mu_h
\end{align*}
Then let us assume that $a_t \equiv 0,\ \forall\ t < 1, t > n$. Denote
\begin{align*}
x_i &= \begin{pmatrix}
a_{i+1}\\
a_{i+2}\\
\dots\\
\dots\\
a_{i+n}
\end{pmatrix}\\
\sum_{i = -n + 1}^{n-1} x_i x_i^T &= \begin{pmatrix}
\mu_0 & \mu_1 & \mu_2 & \dots & \mu_{n-1}\\
\mu_1 & \mu_0 & \mu_1 & \dots & \mu_{n-2}\\
\dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots \\
\mu_{n-1} & \mu_{n-2} & \mu_{n-3} & \dots & \mu_0
\end{pmatrix} = M
\end{align*} 
\begin{align*}
\forall\ v \in \mathbb{R}^{n}\ v^TMv = \sum_{i=-n+1}^{n-1} v^Tx_ix_i^Tv = \sum_{i=-n+1}^{n-1} (x_i^Tv)^T(x_i^Tv) \ge 0
\end{align*}
That is matrix, $M$ is positive semi-definite. Denote vector $s \in \mathbb{R}^n$ such that first $g+1$ entries are 1 and other are 0. Then
\begin{align*}
\frac{1}{g+1}s^TMs = \mu_0 + 2\frac{g}{g+1}\mu_1 + 2\frac{g-1}{g+1}\mu_2 + \dots + 2 \frac{1}{g+1}\mu_g = \hat{\nu} \ge 0
\end{align*}
Q.E.D.


\section*{Problem 3}
\begin{enumerate}[(i)]
	\item 12 $\hat{h}_t$ are negative.
	\item No, there are no negative $\hat{h}_t$
	\item Estimating WLS one can get
	\begin{center}
		\begin{tabular}{lc} \hline
			& (1) \\
			VARIABLES & return \\ \hline
			&  \\
			return\_1 & 0.0389 \\
			& (0.0455) \\
			Constant & 0.155** \\
			& (0.0780) \\
			&  \\
			Observations & 689 \\
			R-squared & 0.001 \\ \hline
			\multicolumn{2}{c}{ Robust standard errors in parentheses} \\
			\multicolumn{2}{c}{ *** p$<$0.01, ** p$<$0.05, * p$<$0.1} \\
		\end{tabular}
	\end{center}
while usual OLS regression yields:
\begin{center}
	\begin{tabular}{lc} \hline
		& (1) \\
		VARIABLES & return \\ \hline
		&  \\
		return\_1 & 0.0589 \\
		& (0.0692) \\
		Constant & 0.180** \\
		& (0.0853) \\
		&  \\
		Observations & 689 \\
		R-squared & 0.003 \\ \hline
		\multicolumn{2}{c}{ Robust standard errors in parentheses} \\
		\multicolumn{2}{c}{ *** p$<$0.01, ** p$<$0.05, * p$<$0.1} \\
	\end{tabular}
\end{center}
So as we can see, $\hat{\beta}_1$ becomes smaller but the significance remains unchanged. The hypothesis $H_0: \beta_1 = 0$ cannot be rejected even at 10\% significance level.
\item The results are depicted below
\begin{center}
\begin{tabular}{lc} \hline
	& (1) \\
	VARIABLES & return \\ \hline
	&  \\
	return\_1 & 0.0239 \\
	& (0.0466) \\
	Constant & 0.159** \\
	& (0.0783) \\
	&  \\
	Observations & 688 \\
	R-squared & 0.000 \\ \hline
	\multicolumn{2}{c}{ Robust standard errors in parentheses} \\
	\multicolumn{2}{c}{ *** p$<$0.01, ** p$<$0.05, * p$<$0.1} \\
\end{tabular}
\end{center}
As we can see $\hat{\beta}_1$ becomes even smaller. It does not change our findings from (iii), the hypothesis that $\beta_1 = 0$ still cannot be rejected.
\end{enumerate}

\section*{Problem 4}
\begin{enumerate}[(i)]
	\item Running regression $\hat{u}_{t}$ on $\hat{u}_{t-1}$ one can get $\hat{\rho} \approx 0.282$ with t-statistics 3.25. Hence the hypothesis $\rho =0$ is rejected at 5\% significance level, i.e. we cannot reject the hypothesis of presence of serial correlation.
	Obviously time trend, monthly dummies and $wkends$ are strictly exogenous, it is determined variables. Also unemployment rate seems to be strictly exogenous because it seems that today's unexpected changes in fatal accident rate cannot affect future unemployment. However, law-variables do not seem to be strictly exogenous because the law can be enacted due to extremely high fatal accident rate, hence today's $u_t$ can predict future laws' enactment.
	
	\item Results for the usual OLS (column 1) and serial correlation- and heteroskedasticity robust (column 2) are depicted below
	\begin{center}
	\begin{tabular}{lcc} \hline
		& (1) & (2) \\
		VARIABLES & prcfat & prcfat \\ \hline
		&  &  \\
		t & -0.00224*** & -0.00224*** \\
		& (0.000458) & (0.000559) \\
		\dots \dots \dots\\
		wkends & 0.000626 & 0.000626 \\
		& (0.00585) & (0.00516) \\
		unem & -0.0154** & -0.0154** \\
		& (0.00604) & (0.00602) \\
		spdlaw & 0.0671*** & 0.0671** \\
		& (0.0198) & (0.0267) \\
		beltlaw & -0.0295 & -0.0295 \\
		& (0.0237) & (0.0331) \\
		Constant & 1.030*** & 1.030*** \\
		& (0.0959) & (0.0938) \\
		&  &  \\
		Observations & 108 & 108 \\
		R-squared & 0.717 &  \\ \hline
		\multicolumn{3}{c}{ Robust standard errors in parentheses} \\
		\multicolumn{3}{c}{ *** p$<$0.01, ** p$<$0.05, * p$<$0.1} \\
	\end{tabular}
	\end{center}
As we can see the significance of coefficient on $spdlaw$ decreases but it remained significant at 5\%. $beltlaw$ remained not significant its t-statistics becomes lower.
\item The regression output is depicted below
\begin{center}
	\begin{tabular}{lc} \hline
		& (1) \\
		VARIABLES & prcfat \\ \hline
		&  \\
		t & -0.00215*** \\
		& (0.000548) \\
		\dots \dots \\
		wkends & 0.000617 \\
		& (0.00500) \\
		unem & -0.0132* \\
		& (0.00711) \\
		spdlaw & 0.0641** \\
		& (0.0268) \\
		beltlaw & -0.0248 \\
		& (0.0301) \\
		Constant & 1.009*** \\
		& (0.102) \\
		&  \\
		Observations & 108 \\
		R-squared & 0.641 \\ \hline
		\multicolumn{2}{c}{ Standard errors in parentheses} \\
		\multicolumn{2}{c}{ *** p$<$0.01, ** p$<$0.05, * p$<$0.1} \\
	\end{tabular}
\end{center}
There are no changes both in significance of coefficients and their values.
\end{enumerate}
\end{document}