\documentclass[a4paper]{article}
\usepackage[14pt]{extsizes} % 
\usepackage[utf8]{inputenc}
\usepackage{setspace,amsmath}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{titlesec}
\usepackage{pdfpages}
\usepackage[shortlabels]{enumitem}
\usepackage{tikz}
\usetikzlibrary{angles,quotes}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{float}
\usepackage{makecell}
\usepackage[section]{placeins}
\usepackage[makeroom]{cancel}
\usepackage{mathrsfs} % 
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%\addto\captionsrussian{\renewcommand{\figurename}{Fig.}}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} 
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
{\hbox{$\mathsurround=0pt #1$}}{}}
\usepackage{graphicx}  % 
\graphicspath{{images/}{images2/}}  % 
\setlength\fboxsep{3pt} %  \fbox{} 
\setlength\fboxrule{1pt} % \fbox{}
\usepackage{wrapfig} % 
\newcommand{\prob}{\mathbb{P}}
\newcommand{\norma}{\mathscr{N}}
\newcommand{\expect}{\mathbb{E}}
\newcommand{\summa}{\sum_{i=1}^n}
\newcommand{\yrseduc}{\textit{yrseduc}}
\usepackage[left=7mm, top=20mm, right=15mm, bottom=20mm, nohead, footskip=10mm]{geometry} % 
\usepackage{tikz} % 
\def\myrad{2cm}% radius of the circle
\def\myanga{45}% angle for the arc
\def\myangb{195}
\begin{document} % 
	\begin{flushright}
	\begin{tabular}{r}
		Danil Fedchenko, MAE 2020, group A \\
	\end{tabular}
\end{flushright}


\begin{center}
	Econometrics 1. Problem Set 5.
\end{center}
\section*{Problem 1}
Consider a simple model to estimate the effect of personal computer (PC) ownership on
college grade point average for graduating seniors at a large public university:
\begin{align*}
GPA = \beta_0 + \beta_1 PC + u
\end{align*}
where $PC$ is a binary variable indicating $PC$ ownership.
\begin{enumerate}[(i)]
\item Why might PC ownership be correlated with $u$?
\item Explain why $PC$ is likely to be related to parents’ annual income. Does this mean
parental income is a good IV for $PC$? Why or why not?
\item Suppose that, four years ago, the university gave grants to buy computers to roughly
one-half of the incoming students, and the students who received grants were randomly chosen.
Carefully explain how you would use this information to construct an instrumental variable for
$PC$.
\end{enumerate}


\textbf{Solution}


\begin{enumerate}[(i)]
	\item Variety of reasons are possible. For example, people who own PCs can spend a lot of time on playing computer games, as a result they pay less attention to studying, hence their GPA can be affected. That is, error term contains for example a number of hours a person spend on computer games, which of course correlated with PC ownership.
	\item PC is not very cheap purchase, so it can in principle be related to parents' income: smaller income - smaller probability that parents can afford purchasing a PC. Parental income is good IV if it is valid, i.e. is not correlated with error term. As for me, it is not a good IV because I suppose that children from not very rich families can tend to have a higher motivation for studying than their rich counterparts, as a result parental income can be negatively correlated with $GPA$.
	\item We can use as IV a dummy variable, whether or not a particular student have been chosen as a grant taker. Obviously it is not correlated with $GPA$ because students were chosen randomly. Moreover this variable is correlated with PC ownership, because once the person received a grant for purchasing PC, he should own a PC. Consequently, this variable is relevant, i.e. correlated with PC ownership, and exogenous, i.e. not correlated with $GPA$.
\end{enumerate}
\section*{Problem 2}
Consider a simple linear regression model
\begin{align*}
y = \beta_0 + \beta_1x + u
\end{align*}
The regressor $x$ is endogenous and $Cov(x, u) \neq 0$. There are two instruments $z_1$ and $z_2$, which
are valid and relevant and non-constant. The error term $u$ is homoscedastic and has zero
unconditional mean. The random variables $x$, $z_1$ and $z_2$ also have zero unconditional mean.
\begin{enumerate}[(a)]
\item Suppose that $Cov(x, u) > 0$. What is the sign of an asymptotic bias of the OLS estimate
of the intercept?
\item Consider the vector of random variables $\xi = (x, z_1, z_2)^T$. What is a minimal possible
rank of the following matrix of expectations: $\expect (\xi\xi^T)$?
\item Consider two IV estimates of the intercept. The first estimate is based on the following
two instruments: constant and $z_1$. The second is based on $z_1$ and $z_2$. Is it possible to get
a smaller asymptotic variance for the intercept estimator in the second case than in the first
case? If yes, provide an example.
\item Suppose someone wants to perform IV estimation with the following instruments: constant and $z_1$. The estimator does not observe $z_1$, instead (s)he observes this variable with a
measurement error which is i.i.d. and independent of all other random variables. Investigate
and describe the effect of the measurement error on efficiency of estimation.
\end{enumerate}


\textbf{Solution}


\begin{enumerate}[(a)]
	\item If $Cov(x, u) > 0$ then
	\begin{align*}
	\frac{\summa (x_i - \bar{x})y_i}{\summa (x_i - \bar{x})^2} = \hat{\beta}_1 \overset{p}{\to} \frac{cov(x, y)}{Var(y)} = \beta_1 + \frac{cov(x, u)}{Var(x)}
	\end{align*}
	\begin{align*}
	\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} = \beta_0 + (\beta_1 - \hat{\beta_1})\bar{x} + \bar{u} \overset{p}{\to} \beta_0 + \frac{cov(x, u)}{Var(x)}\expect x + \expect u = \beta_0
	\end{align*}
	hence the intercept is still asymptotically unbiased.
	\item $\expect \xi \xi^T$ is in fact a covariance matrix of the random vector $\xi = (x\ z_1\ z_2)^T$, i.e. $Var(\xi)$. Assume firstly that $z_1$ and $z_2$ are perfectly linearly dependent i.e. $z_1 = -\alpha z_2, \alpha \neq 0$. That means that
	\begin{align*}
	\exists\ v = (0\ 1\ -\alpha)^T \neq 0: Var(v^T\xi) = v^T Var(\xi) v = Var(z_1 -\alpha z_2) = 0
	\end{align*}
	that means that matrix $Var(\xi) = \expect (\xi \xi^T)$ is singular, i.e. $rg(\expect(\xi\xi^T)) < 3$. Note that assumption of perfect linear dependency between $z_1$ and $z_2$ does not violate the premise of the problem, both $z_1$ and $z_2$ are still valid, relevant and non-constant. In conclusion, rank can be equal to 2.
	
	Now assume that $x = \alpha_1 z_1 + \alpha_2 z_2,\  \alpha_1\alpha_2 \neq 0$ then
	\begin{align*}
	\expect x^2 = \expect[\alpha_1^2z_1^2 + 2\alpha_1\alpha_2z_1z_2 + \alpha_2^2z_2^2] = \alpha_1\expect[\alpha_1z_1^2 + \alpha_2z_1z_2] + \alpha_2\expect[\alpha_1z_1z_1 + \alpha_2z_2^2] =\\ =\alpha_1\expect[xz_1] + \alpha_2 \expect[xz_2]
	\end{align*}
	As a result:
	\begin{align*}
	Varx = \alpha_1 cov(x, z_1) + \alpha_2 cov(x, z_2)\\
	cov(x, z_1) = \alpha_1 Varz_1 + \alpha_2 cov(z_1, z_2)\\
	cov(x, z_2) = \alpha_1 cov(z_1, z_2) + \alpha_2Varz_2
	\end{align*}
	Since
	\begin{align*}
	\expect \xi\xi^T = \begin{pmatrix}
	Varx & cov(x, z_1) & cov(x, z_2)\\
	cov(x, z_1) & Var z_1 & cov(z_1, z_2)\\
	cov(x, z_2) & cov(z_1, z_2) & Varz_2
	\end{pmatrix}
	\end{align*}
	we can conclude that the first row is a linear combination of two other rows, i.e. matrix has rank 1.
	
	However, in this case $z_1$ and $z_2$ become non-valid instruments, because
	\begin{align*}
	cov(u, z_1) = \frac{1}{\alpha_1}cov(x, u) - \frac{\alpha_2}{\alpha_1}cov(z_2, u) = \frac{1}{\alpha_1}cov(x, u) \neq 0\\
	cov(u, z_2) = \frac{1}{\alpha_2}cov(x, u) - \frac{\alpha_1}{\alpha_2}cov(z_1, u)= \frac{1}{\alpha_2}cov(x, u) \neq 0\\
	\end{align*}
	In conclusion, minimal rank is 2.
	\item Assume $x_i = (1\ x_i)^T, X = (x_1\ \dots\ x_n)^T, z_{1i} = (1\ z_{1i})^T, Z_1 = (z_{11}\ \dots\ z_{1n})^T, \beta = (\beta_0\ \beta_1)^T$.
	Then 
	\begin{align*}
	y &= X\beta + u\\
	X &= Z_1\gamma + v\\
	y &= Z_1\gamma\beta + u\\
	\hat{\beta} &= ((Z_1\hat{\gamma})^T(Z_1\hat{\gamma}))^{-1}(Z_1\hat{\gamma})^Ty\\
	\hat{\gamma} &= (Z^TZ_1)^{-1}Z_1^TX\\
	\hat{\beta}&=(X^TZ_1(Z_1^TZ_1)^{-1}Z_1^TX)^{-1}X^TZ_1(Z_1^TZ_1)^{-1}Z_1^Ty = (Z_1^TX)^{-1}Z_1^Ty\\
	Var(\hat{\beta}) &= (Z_1^TX)^{-1}Z_1^TZ_1(X^TZ_1)^{-1}\sigma^2\\
	\end{align*}
	\begin{align*}
	\frac{1}{n}(Z_1^TX) = \begin{pmatrix}
	1 & \bar{x}\\
	\bar{z_1} & \frac{1}{n}\summa z_{1i}x_i
	\end{pmatrix} &\overset{p}{\to} \begin{pmatrix}
	1 & 0\\
	0 & cov(z_1, x)
	\end{pmatrix}\\
	\frac{1}{n}(Z^TZ) = \begin{pmatrix}
	1 & \bar{z}\\
	\bar{z} & \frac{1}{n}\summa z_{1i}^2
	\end{pmatrix} &\overset{p}{\to} \begin{pmatrix}
	1 & 0\\
	0 & Var(z_1)
	\end{pmatrix}\\
	\frac{1}{n} (X^TZ_1) = \begin{pmatrix}
	1 & \bar{z_1}\\
	\bar{x} & \frac{1}{n}\summa z_{1i}x_i
	\end{pmatrix} & \overset{p}{\to} \begin{pmatrix}
	1 & 0\\
	0 & cov(z_1, x)
	\end{pmatrix}
	\end{align*}
	That means that $n Var_{as}(\hat{\beta_0}) = \sigma^2$
	
	
	Now, suppose $z_{2i} = (z_{1i}\ z_{2i})^T$ and $Z_2 = (z_1\ \dots\ z_n)^T$. Following the same logic:
	\begin{align*}
	Var(\hat{\beta}) = (Z_2^TX)^{-1}Z_2^TZ_2(X^TZ_2)^{-1}\sigma^2\\
	\end{align*}
	\begin{align*}
	\frac{1}{n}(Z_2^TX) = \begin{pmatrix}
	\bar{z_1} & \frac{1}{n}\summa z_{1i}x_i\\
	\\
	\bar{z_2} & \frac{1}{n}\summa z_{2i}x_i
	\end{pmatrix} &\overset{p}{\to} \begin{pmatrix}
	0 & cov(z_1, x)\\
	0 & cov(z_2, x)
	\end{pmatrix}\\
	\frac{1}{n}(Z^TZ) = \begin{pmatrix}
	\frac{1}{n}\summa z_{1i}^2 & \frac{1}{n}\summa z_{1i}z_{2i}\\
	\\
	\frac{1}{n}\summa z_{2i}x_i & \frac{1}{n}\summa z_{2i}^2
	\end{pmatrix} &\overset{p}{\to} \begin{pmatrix}
	Var(z_1) & cov(z_1, z_2)\\
	cov(z_1, z_2) & Var(z_2)
	\end{pmatrix}\\
	\frac{1}{n} (X^TZ_1) = \begin{pmatrix}
	\bar{z_1} & \bar{z_2}\\
	\frac{1}{n}\summa x_iz_{1i} & \frac{1}{n}\summa z_{2i}x_i
	\end{pmatrix} & \overset{p}{\to} \begin{pmatrix}
	0 & 0\\
	cov(x, z_1) & cov(z_2, x)
	\end{pmatrix}
	\end{align*}
	As we can see, asymptotic matrix is singular, i.e. it diverges to infinity whereas in previous case asymptotic variance $\times n$ is finite. We have to conclude that, it is not possible to get
	a smaller asymptotic variance for the intercept estimator in the second case than in the first
	case.
	\item Assume $\tilde{z_{1i}} = z_{1i} + \varepsilon_i$. Then
	\begin{align*}
	\hat{\beta_1}_{IV} &= \frac{\summa (y_i - \bar{y})(z_{1i} + \varepsilon_i)}{\summa (x_i - \bar{x})(z_{1i} + \varepsilon_i)}\\
	Var(\hat{\beta_1}_{IV}|x, \tilde{z_1}) &= \frac{s^2_{z_1z_1} + 2s^2_{z_1\varepsilon} + s^2_{\varepsilon \varepsilon}}{(s^2_{xz_1} + s^2_{x \varepsilon})^2}\sigma^2 \overset{p}{\to} \frac{Var(z_1) + Var(\varepsilon)}{(cov(x, z_1))^2}\sigma^2
	\end{align*}
	As we can observe, the error term affects asymptotic effectiveness of estimator, variance becomes larger.
\end{enumerate}
\section*{Problem 3}
\begin{enumerate}[(a)]
	\item If we suppose that wealth level remains unchanged in both cases (the expenditure on purchase is insufficiently small comparing to the whole wealth) then correlation should be positive, because if $p_{i0}$ is larger that means that on average $w_i$ is large, which means that $p_{1i}$ is also on average large.
	\item Of course $cov(p_{i0}, \varepsilon_{i}^1) = 0$ i.e. the instrumental variable is exogenous. It remains to show that it is relevant. Obviously, by the set-up of the problem $cov(p_{i0}, w_i) > 0$. Moreover, as it has been stated in (a):
	\begin{align*}
	cov(p_{i0}, \beta_2w_i) > 0\\
	cov(p_{i0}, \beta_2w_i + \varepsilon_i^1) > 0\\
	cov(p_{i0}, f(\beta_2w_i + \varepsilon_i^1)) > 0\\
	cov(p_{i0}, p_{i1}) > 0
	\end{align*}
	Thus, the IV is exogenous and relevant i.e. valid. Assume $p_i = A \cdot (\beta_2 w_i + \varepsilon_i) + B$ then
	\begin{align*}
	\frac{1}{n} (Z^TX) \overset{p}{\to} \begin{pmatrix}
	1 & A\beta_2 \expect [w] + B & \expect[w]\\
	A\beta_2\expect[w] + B & A^2\beta_2^2\expect[w^2] + 2AB\beta_2\expect[w]& A\beta_2 \expect[w^2]+B\expect[w]\\
	\expect[w]& A\beta_2 \expect[w^2]+B\expect[w] & \expect[w^2]
	\end{pmatrix}
	\end{align*}
	it is easy to see that determinant of this matrix is equal to
	\begin{align*}
	B^2 (\expect[w])^2
	\end{align*}
	As a result, if $B = 0$ then the aforementioned matrix is singular that means that asymptotic variance of estimator diverges to infinity (not well-behaved)
	\item To find OLS estimates we need to solve the following linear system:
	\begin{align*}
	(X^TX) \hat{\beta} = X^Ty\\
	\end{align*}
	Since the inverse operation is interchangeable with convergence in probability (continuous mapping theorem) hence, the limit in probability of the solution to the system must coincide with the solution of system, which is obtained in limit. That is,
	\begin{align*}
	\text{If } \beta_n \overset{p}{\to} \beta\ \&\ X_n \overset{p}{\to} X, y_n \overset{p}{\to} y\ \text{ then }\\
	\text{If } \forall\ n\ X_n^TX_n\beta_n = X^T_ny_n\text{ then } X^TX \beta = X^Ty
	\end{align*}
	\begin{align*}
	\frac{1}{n} X^T_nX_n \gamma_n &= \frac{1}{n}X_n^Ty_n\\
	\begin{pmatrix}
	1 & \expect[p_0] & \expect[w]\\
	\expect[p_0] & \expect[p_0^2] & \expect[p_0w]\\
	\expect[w] & \expect[p_0w] & \expect[w^2]
	\end{pmatrix} \begin{pmatrix}
	\gamma_0\\
	\gamma_1\\
	\gamma_2
	\end{pmatrix} &= \begin{pmatrix}
	\expect[q_1]\\\expect[p_0q_1]\\
	\expect[wq_1]
	\end{pmatrix}\\
	\end{align*}
	\begin{align*}
	\begin{pmatrix}
	1 & \expect[p_0] & \expect[w] \bigg| \expect[q_1]\\
	\expect[p_0] & \expect[p_0^2] & \expect[p_0w]\bigg| \expect[p_0q_1]\\
	\expect[w] & \expect[p_0w] & \expect[w^2]\ \bigg|\expect[wq_1]
	\end{pmatrix} &\sim \begin{pmatrix}
	1 & \expect[p_0] & \expect[w] \bigg| \expect[q_1]\\
	\expect[p_0] & \expect[p_0^2] & \expect[p_0w]\bigg| \expect[p_0q_1]\\
	0 & cov(p_0,w) & Var(w)\ \ \  \bigg|cov(w,q_1)
	\end{pmatrix} \sim \\
	&\sim \begin{pmatrix}
	1 & \expect[p_0] & \expect[w] \bigg| \expect[q_1]\\
	0 & Var(p_0) & cov(p_0, w)\bigg| cov(p_0q_1)\\
	0 & cov(p_0, w) & Var(w)\ \ \ \bigg|cov(w, q_1)
	\end{pmatrix} 
	\end{align*}
	\begin{align*}
	&\gamma_2 = \frac{cov(w, q_1)Var(p_0) - cov(p_0, w)cov(p_0, q)}{Var(w)Var(p_0) - (cov(p_0, w))^2}\\
	&\gamma_1 = \frac{cov(p_0, q_1)Var(w) - cov(p_0, w)cov(w, q)}{Var(w)Var(p_0) - (cov(p_0, w))^2}\\
	&\gamma_0 = \expect[q_1] - \expect[p_0] \beta_1 - \expect[w]\beta_2
	\end{align*}
	\item 
	\begin{align*}
	&q_i^1 - q_i^0 = \beta_1(p_i^1 - p_i^0) + \varepsilon_i^1 - \varepsilon_i^0\\
	&\hat{\gamma_1} = \frac{\summa (q^1_i - \bar{q^1} - q^0_i + \bar{q^0})(p^1_i - \bar{p^1} - p^0_i + \bar{p^0})}{\summa (p^1_i - \bar{p^1} - p^0_i + \bar{p^0})^2} = \\
	&= \frac{\summa (\beta_1(p_i^1 - p_i^0) + \varepsilon_i^1 - \varepsilon^0_i - \beta_1(\bar{p^1} - \bar{p^0}) - \bar{\varepsilon^1} + \bar{\varepsilon^0})(p^1_i - \bar{p^1} - p^0_i + \bar{p^0})}{\summa (p^1_i - \bar{p^1} - p^0_i + \bar{p^0})^2}
	\end{align*}
	\begin{align}\label{eq1}
	\expect[\hat{\gamma_1}] = \expect[\expect[\hat{\gamma_1}|p^1, p^0]] = \beta_1 +  \expect\left[\frac{\summa (p^1_i - \bar{p^1} - p^0_i + \bar{p^0})(f^{-1}(p^1_i) - f^{-1}(p^0_i))}{\summa (p^1_i - \bar{p^1} - p^0_i + \bar{p^0})^2}\right]
	\end{align}
	where $f(\cdot)$ is such a function that:
	\begin{align*}
	p^0_i = f(\beta_2 w_i + \varepsilon^0_i)\\
	p^1_i = f(\beta_2 w_i + \varepsilon^1_i)\\
	\end{align*}
	There are no reasons for the second term in \eqref{eq1} to have a zero mean, that means that $\hat{\gamma_1}$ is biased.
	\item 
	\begin{align}\label{eq2}
	\frac{1}{n}(Z^TX) \overset{p}{\to} \begin{pmatrix}
	1 & \expect[p^1] & \expect[w]\\
	\expect[p^0] & \expect[p^1p^0] & \expect[p^0w]\\
	\expect[w] & \expect[p^1w] & \expect[w^2]
	\end{pmatrix} \sim \begin{pmatrix}
	1 & \expect[p^1] & \expect[w]\\
	0 & cov(p^1, p^0) & cov(p^0, w)\\
	0 & cov(p^1, w) & Var(w)
	\end{pmatrix}\\
	\det \begin{pmatrix}
	1 & \expect[p^1] & \expect[w]\\
	0 & cov(p^1, p^0) & cov(p^0, w)\\
	0 & cov(p^1, w) & Var(w)
	\end{pmatrix} = cov(p^1, p^0)Var(w) - cov(p^1, w)cov(p^0, w)\nonumber
	\end{align}
	By the Cauchy - Schwartz inequality
	\begin{align*}
	|cov(p^1, w)| \le \sqrt{Var(p^1)Var(w)}
	\end{align*}
	If $p^1 = [\beta_2 w + \varepsilon^1]^3, p^0 = [\beta_2 w + \varepsilon^0]^3$ then $cov(p_1, w) \ge 0$ hence:
	\begin{align*}
	cov(p^1, p^0)Var(w) - cov(p^1, w)cov(p^0, w) \ge cov(p^1, p^0)Var(w) - \\
	-\sqrt{Var(p^1)Var(p^0)}Var(w) > Var(w) > 0
	\end{align*}
	Since $cor(p^1, p^0) < 1$ because $p^1, p^0$ are not linearly dependent. That means that determinant of the matrix \eqref{eq2} is not zero, i.e. the estimator is well behaved asymptotically.	
\end{enumerate}
\section*{Problem 4}
Estimate the own-price elasticity of demand by using OLS to regress the log of the quantity
of grain shipped on the log of the price of shipping grain and the full set of month binary
indicators.
\begin{enumerate}[(a)]
\item What is the estimated demand elasticity and its standard error?
\item Explain why the interaction of supply and demand plausibly makes this estimator of
the elasticity biased.
\end{enumerate}


\textbf{Solution}

\begin{enumerate}[(a)]
	\item The output of coeftest() is depicted below
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\textwidth]{price_elasticity}
		\caption{}\label{fig1}
	\end{figure}
	Elasticity is equal to -0.25 and its standard error is equal to 0.029.
	\item The estimated model is
	\begin{align*}
	\ln (quantity) = \beta_0 + \beta_1 \ln (price) + \beta_2 seas1 + \cdot \beta_{13} seas12 + u
	\end{align*}
	Where $u$ is the error term, which includes all factors which affect quantity sold apart from price and dummy months variables. This term can include for example, prices of substitutes (the cheaper substitutes are the smaller quantity) or total income of people (the poorer people are the smaller quantity is). However, price is obviously correlated with aforementioned factors: the less substitutes cost the smaller price is, that means that assumption of OLS is violated, which leads to biased estimate of elasticity.
\end{enumerate}
\section*{Problem 5}
Consider two possibilities for instrumental variables: whether the railroad cartel was experiencing one of its periodic collapses ($cartel$), and whether the Great Lakes are closed because
of ice ($ice$).
\begin{enumerate}[(a)]
\item Use economic reasoning to argue whether $cartel$ plausibly satisfies the two conditions
for a valid instrument.
\item Use economic reasoning to argue whether $ice$ plausibly satisfies the two conditions for
a valid instrument
\end{enumerate}

\textbf{Solution}

\begin{enumerate}[(a)]
	\item Without doubt $cartel$ is correlated with $quantity$ (sample covariance is about 0.6). As it has been described cartels try to raise prices. Moreover, the existence of cartel can hardly affect the demand on grain, neither preferences nor income or prices of substitutes can be affected by existence of cartel, hence it is plausibly a valid instrument.
	\item As in previous case, whether or not lakes are covered with ice cannot affect the consumers' demand for grain, however sample correlation between $ice$ and $\ln (price)$ is rather small (0.3) i.e. $ice$ can be a weak instrument.
\end{enumerate}
\section*{Problem 6}
\begin{center}
\begin{tabular}{cccccc}
	\hline
	& (1) & (2) & (3) & (4) & (5)\\
	\hline\\
	Dependent variable: & $\ln(P)$ & $\ln(Q)$ & $\ln(Q)$ & $\ln(Q)$ & $\ln(Q)$\\
	Regressors:& & & &\\
	cartel & $\underset{(13.6534)}{0.356}$ & – & – & – & –\\
	ln(P) & – & $\underset{(-8.7779)}{-0.662}$ & $\underset{(-6.9133)}{-0.93}$ & $\underset{(-1.7509)}{-4.74}$ &$\underset{(-6.7985)}{-0.921}$\\
	\makecell{F-statistic testing\\
	coefficients on monthly\\
	indicators (p-value)} &5.298e-08 & 1.725e-14&2.2e-16 & 0.6864&2.2e-16\\
	Estimation method & OLS & OLS &TSLS &TSLS &TSLS\\
	Instrumental variables& n/a& n/a& cartel& ice& \makecell{ice\\
	cartel}\\
	First-stage F-statistic& n/a &n/a&186.42&2.3907&92.847\\
	J-test of overidentifying &n/a &n/a&&&\\
	restrictions & n/a &n/a &n/a& n/a&
\end{tabular}
\end{center}
\section*{Problem 7}
I think the most reasonable results were gotten in TSLS regression with $cartel$ as IV. As we can conclude from F-statistic, $ice$ is a weak instrument which is barely correlated with prices and I think only add noise to the model. On the other hand, $cartel$ is correlated with prices, and give reasonable significant statistics to conclude that there was indeed cartel pricing (elasticity is very close to -1).

Here, the main threat is a weak correlation between instruments and regressors
\end{document}