\documentclass[a4paper]{article}
\usepackage[12pt]{extsizes} % 
\usepackage{setspace}
\doublespacing
\usepackage[utf8]{inputenc}
\usepackage{setspace,amsmath}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{titlesec}
%\usepackage{harvard}
\usepackage[round]{natbib}
\usepackage{pdfpages}
\usepackage{tikz}
\usepackage{makecell}
\usepackage{amsthm}
\usepackage[shortlabels]{enumitem}
\usepackage{tikz}
\usepackage{multirow}
\usetikzlibrary{angles,quotes}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{xcolor,colortbl}
\usepackage{amssymb}
\usepackage{float}
\usepackage[affil-it]{authblk}
\usepackage[section]{placeins}
\usepackage{breakcites}
\interfootnotelinepenalty=10000
\usepackage[makeroom]{cancel}
\usepackage{mathrsfs} % 
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
%\addto\captionsrussian{\renewcommand{\figurename}{Fig.}}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} 
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
	{\hbox{$\mathsurround=0pt #1$}}{}}
\usepackage{graphicx}  % 
\graphicspath{{images/}{images2/}}  % 
\setlength\fboxsep{3pt} %  \fbox{} 
\setlength\fboxrule{1pt} % \fbox{}
\usepackage{wrapfig} % 
%\newenvironment{abstract}[0]{\small\rm
%	\begin{center}ABSTRACT
%		\\ \vspace{8pt}
%		\begin{minipage}{5.2in}\smalllineskip
%			\hspace{1pc}}{\end{minipage}\end{center}\vspace{-1pt}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\norma}{\mathcal{N}}
\renewcommand*{\Affilfont}{\normalfont}
\newcommand{\expect}{\mathbb{E}}
\newcommand{\posder}{u^{(k)}_{+}}
\newcommand{\negder}{u^{(k)}_{-}}
\newcommand{\eps}{\varepsilon}
\newcommand{\summa}{\sum_{i=1}^n}
\usepackage[left=25mm, top=20mm, right=25mm, bottom=20mm, nohead, footskip=10mm]{geometry} % 
\usepackage{tikz} % 
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{observation}[theorem]{Observation}
%\let\cite = \citeasnoun
\title{Zero derivative and local risk aversion}
\author{Danil Fedchenko\thanks{I thank Eddie Dekel for help and suggestions. Any remaining errors are mine. }}
\affil{Northwestern University}
\date{\today}
\begin{document} % 
	\maketitle
	\begin{abstract}
	Consider a random variable $\varepsilon$ such that $\expect[\varepsilon] = 0$. Denote $\pi(t, x)$ a risk premium, an expected-utility maximizer with Bernoulli utility $u(x)$ is willing to pay to avoid risk $t \varepsilon$ (i.e. $u(x-\pi(t, x)) = \int u(x+t\varepsilon)dF(\varepsilon)$). As \cite{segal1990first} stated $\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t=0} = 0$ for all $x$, provided that $u'(x) \neq 0$. In this note I show that an attitude toward risk of an individual with $u'(x) = 0$ typically is similar to what \cite{segal1990first} called of order 1. This in particular implies that such an individual may find optimal to buy full insurance even for a small positive risk in the neighborhood of the points where $u'(x) = 0$.
	\end{abstract}
	\newpage
	\section{Introduction}
	Consider an individual with expected utility preferences represented by strictly increasing, continuous Bernoulli utility function $u(x)$. Suppose this individual for some $t \in \mathbb{R}$ faces a lottery $t \eps$ represented by a random variable $\varepsilon$ such that $\expect[\varepsilon] = 0$. Define a risk premium $\pi(t, x)$ implicitly as $x-\pi(t, x) \sim x+t\eps$ or equivalently $u(x - \pi(t, x)) = \int u(x + t \eps)\ dF(\eps)$ (from now on whenever I write $\int$, I assume the integral exists). It is easy to show that as long as $u'(x) \neq 0$, $\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t=0} = 0$. Indeed, 
	\begin{align*}
	\pi(t, x) &= x - u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right) \footnotemark\\
	\frac{\partial \pi(t, x)}{\partial t} &= -\left(u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right) \right)' \int u'(x+t \varepsilon)\varepsilon dF(\varepsilon) = \\
	&=-\frac{\int u'(x+t \varepsilon)\varepsilon dF(\varepsilon)}{u'\left(u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right)\right)}\ ,\ \ \  \text{if }u'\left(u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right)\right) \neq 0\\
	\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t=0} &= -\frac{u'(x)}{u'(x)} \expect[\eps] = -\expect[\eps] = 0, \text{ if } u'(x) \neq 0
	\end{align*}
\footnotetext{$u^{-1} \text{ exists since }u(x)\text{ is strictly increasing and continuous}$}
Using this and continuing similarly one can show that for small enough $t$ $$\pi(t, x) \approx -\frac{t^2 \expect[\eps^2]}{2}\frac{u''(x)}{u'(x)}$$ and hence it approaches zero faster than $t$ which, in turn, implies that for small $t$ an individual is almost risk neutral. This assertion, however, relies upon the assumption $u'(x) \neq 0$ which may not only be violated for strictly increasing functions at some point ($u(x) = x^3$ at $x=0$ is probably the most famous example) but even more so, there exist strictly increasing and continuous functions whose derivative equals zero almost everywhere. 


In this paper, in Section \ref{order},  I derive $\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t=0}$ at points where $u'(x) = 0$, and show that it is not equal to zero in general\footnote{One might mistakenly conjecture  that if $\frac{\partial \pi(t, x_n)}{\partial t}\bigg|_{t=0}=0$ for some $x_n \underset{n \to \infty}{\to}x$, then $\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t=0}=0$, but our results show such a conjecture is typically false. Which means that $\frac{\partial \pi(t, x)}{\partial t}$ typically is not continuous at $(0, 0)$}. In Section \ref{insurance}, I apply this to the optimal insurance problem and show that an expected utility maximizer whose Bernoulli utility has zero derivative at some point may exhibit local risk aversion. That is, such an individual may find optimal to buy full insurance even for small risk and even if insurance includes positive loading. I illustrate this result by deriving a slope of indifference curves of the individual near the certainty line on the state-contingent Â \cite{yaari1978some}-type diagram where we see that the slope differs from the case where $u'(x) \neq 0$. In Section \ref{Bsingular}, I do the same exercise considering an individual whose Bernoulli utility function is strictly increasing, continuous but has zero derivative almost everywhere. Finally, in Section \ref{Examples}, I consider several concrete examples which illustrate general results derived in the previous sections. 
\section{Order of Risk Aversion}\label{order}
\cite{segal1990first} define an attitude toward risk of individual being of order 1 if for every non-degenerate random variable $\eps$ such that $\expect[\eps] = 0$, $\frac{\partial \pi(t, x)}{\partial t} \bigg|_{t = 0^+} \neq 0$ for all $x$, and of order 2 if $\frac{\partial \pi(t, x)}{\partial t} \bigg|_{t = 0^+} = 0$ for all $x$. 
In the next proposition I derive $\frac{\partial \pi(t, x)}{\partial t} \bigg|_{t = 0}$ (assuming that it exists) at a point $x^*$ where for some $k\ge 1$ the first $k-1$ derivatives of the Bernoulli utility function $u(x)$ exist and equal zero. Hereafter I assume that $\pi(t, x)$ is continuous in $t$ at $x^*$.
	\begin{proposition}\label{derivative}
		Suppose $\exists\ x^* \in \mathbb{R}$ and $k \ge 2$ such that $u(x)$ is $k$ times differentiable on $(x^*-\delta, x^*+\delta)$ for some $\delta>0$, and $\forall\ i = \{1, \dots, k-1  \}$: $u^{(i)}(x^*) = 0$, while $u^{(k)}(x^*) \neq 0$. Then if $\expect|\eps^k| < \infty$ and at $x^*$ there exists $\frac{\partial \pi(t, x)}{\partial t} \bigg|_{t = 0}$ :
		\begin{align}
			\left( \frac{\partial \pi(t, x)}{\partial t} \Bigg|_{\substack{t = 0\\x = x^*}} \right)^k = (-1)^k\ \expect[\varepsilon^k]
		\end{align}
	\end{proposition}
\begin{proof}
	By definition of $\pi(t, x)$
	\begin{align*}
		u(x-\pi(t, x)) &= \int u(x+t\eps)dF(\eps)
	\end{align*}
expanding this in the neighborhood of $t=0$ for $x=x^*$ and using $\pi(0, x^*) = 0, u^{(i)}(x^*) = 0\ \forall\ i\in\{1, \dots, k-1\}$, we get
\begin{align}\label{deriva}
	u(x^*) + (-1)^k \frac{u^{(k)}(x^*)}{k!}\pi(t, x^*)^k + o(\pi(t, x^*)^k) &= \int \left(u(x^*) + \frac{u^{(k)}(x^*)t^k\eps^k}{k!}+o(t^k\eps^k) \right)dF(\eps) \nonumber\\
(-1)^k \frac{u^{(k)}(x^*)}{k!}\pi(t, x)^k + \pi(t, x^*)^ko(1) &= \int \left(\frac{u^{(k)}(x^*)t^k\eps^k}{k!}+t^k\eps^ko_{\eps}(1) \right)dF(\eps)
\end{align}
where all $o(\cdot)$ are defined as $t \to 0$.
Since for $t$ small enough $|\eps^ko_{\eps}(1)| < |\eps^k|$ and $\expect|\eps^k|<\infty$, by the dominated convergence theorem $\lim_{t\to0}\expect[\eps^ko_{\eps}(1)] = \expect[\lim_{t\to0}\eps^ko_{\eps}(1)] = 0$, i.e. $\expect[\eps^ko_{\eps}(1)] = o(1), t\to0$.
Then \eqref{deriva} implies
\begin{align}\label{deriv}
	\left(\frac{\pi(t, x^*)}{t}\right)^k = \frac{\left( \frac{u^{(k)}(x^*)\expect[\eps^k]}{k!} + o(1) \right)}{\left( (-1)^k \frac{u^{(k)}(x^*)}{k!} + o(1)) \right)}
\end{align}
Since
\begin{align*}
	\frac{\partial \pi(t, x^*)}{\partial t}\bigg|_{t = 0} = \lim_{t\to0}\frac{\pi(t, x^*)}{t}
\end{align*}
from \eqref{deriv} it follows that
\begin{align*}
	\left( \frac{\partial \pi(t, x)}{\partial t} \bigg|_{\substack{t = 0\\x = x^*}} \right)^k = (-1)^k\ \expect[\varepsilon^k]
\end{align*}
\end{proof}
Thus, if $u'(x) = 0$ the individual's attitude toward risk is in general neither of order 1 nor of order 2, according to \cite{segal1990first} (e.g. for $k=3$ it could be the case $\expect[\eps^3] = 0$) Nevertheless, if it happens to be $\expect[\eps^k] \neq 0$ (where $k$ is defined as in the proposition above) and $\frac{\partial \pi(t, x)}{\partial t}\bigg|_{\substack{t=0\\x = x^*}} \neq 0$, optimal behavior of such an individual regarding the choice of insurance in a neighborhood of $x^*$ is similar to that of the one whose attitude toward risk is of order 1.
\section{Optimal Insurance}\label{insurance}
Discussing the optimal insurance problem, for $t \ge 0$ consider the lottery $x^*+t \eps $ where \textbf{$\expect[\eps] > 0$}. Then, the following proposition is an analogue to Proposition 1 of \cite{segal1990first}.
\begin{proposition}\label{LRA}
	Suppose $\exists\ x^* \in \mathbb{R}$ and $k \ge 2$ such that $u(x)$ is $k$ times differentiable on $(x^*-\delta, x^*+\delta)\setminus\{x^*\}$ for some $\delta>0$, and $\forall\ i = \{1, \dots, k-1  \}$: $u^{(i)}(x^*) = 0$. In addition, there exist finite left and right derivatives $u^{(k)}_{+}(x^*)$ and $u^{(k)}_{-}(x^*)$ such that at least one of these derivatives is non-zero. If there exist finite $\expect| \eps^k |\eps\ge0]$, $\expect[ \eps^k |\eps<0]$ and \begin{align}\label{condition}
		u^{(k)}_{+}(x^*) \cdot \expect[ \eps^k | \eps\ge0]\ \prob(\eps\ge0) + u^{(k)}_{-}(x^*) \cdot \expect[ \eps^k | \eps<0]\ \prob(\eps<0) < 0,
		\end{align}
	then for sufficiently small $t > 0$ \textbf{an individual strictly prefers a certain outcome $x^*$ to the lottery $x^*+t\eps$.}
\end{proposition}
\begin{proof}
	\begin{align*}
		\int u(x^*+t\eps)dF(\eps) = \int \left( u(x^*) +  \bigg[u^{(k)}_{+}(x^*)\mathbb{I}[\eps\ge0]  + u^{(k)}_{-}(x^*)\mathbb{I}[\eps<0] \bigg] \frac{t^k \eps^k }{k!} +o(t^k \eps^k)\right)dF(\eps) = \\
	= u(x^*) + \frac{(u^{(k)}_{+}(x^*) \expect[\eps^k|\eps\ge 0]\prob(\eps\ge0)+u^{(k)}_{-}(x^*) \expect[\eps^k|\eps< 0]\prob(\eps<0))t^k}{k!} + t^k\expect[\eps^k o_{\eps}(1)] < u(x^*)
	\end{align*}
where the first equality follows from Taylor formula and the fact that $\forall\ i = \{1, \dots, k-1 Â \}$: $u^{(i)}(x^*) = 0$, and the last inequality follows from \eqref{condition} and that $\lim_{t\to0}\expect[\eps^ko_{\eps}(1)]=0$, as in the proof of Proposition \ref{derivative} (here $\expect|\eps^k| < \infty$, since there exist finite $\expect[ \eps^k |\eps\ge0]$, $\expect[ \eps^k |\eps<0]$).
\end{proof}
Note that for a $k$ times differentiable $u(x)$, \eqref{condition} becomes $u^{(k)}(x^*)\cdot\expect[\eps^k] < 0$, meaning that if $k$ is the order of first non-zero derivative of $u(x)$ then its sign times the sign of the $k$-th moment determines if the person is locally risk loving or risk averse. 
In other words, the result above means that the expected-utility maximizer under some conditions exhibits local risk aversion (or risk loving) at the vicinity of the points where his strictly increasing Bernoulli utility function fails to have positive derivatives up to the order $k$. Consequently, this individual (in the case of risk-aversion) prefers a certain outcome to the lottery with a small positive expected value. This result stands in contrast to the well-known result that the expected-utility maximizer with increasing Bernoulli utility function $u(x)$ is locally risk neutral as long as $u'(x) > 0$. That is, for $t$ small enough he would strictly prefer the lottery with a positive mean to the certain outcome.





I illustrate Proposition \ref{LRA} by deriving slopes of the individual's indifference curves at a certainty line on the state-contingent diagram. 
Consider an individual whose expected utility preferences are represented by strictly increasing and continuous Bernoulli utility function $u(x)$. Suppose there are two states of nature, the first happens with probability $p$ and the second with probability $1-p$. At state $i \in \{1, 2\}$ the individual gets $x_i$. Then the following proposition holds:
\begin{proposition}\label{slope}
	Suppose $\exists\ x^* \in \mathbb{R}$ and $k \ge 2$ such that $u(x)$ is $k$ times differentiable on $(x^*-\delta, x^*+\delta)\setminus \{x^*\}$ for some $\delta>0$, and $\forall\ i = \{1, \dots, k-1  \}$: $u^{(i)}(x^*) = 0$. In addition, there exist left and right derivatives: $u_{-}^{(k)}(x^*)$, $u_{+}^{(k)}(x^*)$ such that  at least one of these derivatives is non-zero.
	
	
	Then consider an indifference curve $x_2(x_1)$ implicitly given by 
	\begin{align}\label{ind}
		\{ (x_1, x_2): pu(x_1)+(1-p)u(x_2) = u(x^*) \}
	\end{align}
then if there exist $\frac{d x_2}{d x_1} \bigg|_{x_1=x^*+0}$,  $\frac{d x_2}{d x_1} \bigg|_{x_1=x^*-0}$ then
	\begin{align}
		\frac{d x_2}{d x_1} \bigg|_{x_1=x^*+0} = -\sqrt[k]{\frac{p}{1-p} \bigg|  \frac{u^{(k)}_{+}(x^*)}{u^{(k)}_{-}(x^*)} \bigg|  }\\
		\frac{d x_2}{d x_1} \bigg|_{x_1=x^*-0} = -\sqrt[k]{\frac{p}{1-p} \bigg|  \frac{u^{(k)}_{-}(x^*)}{u^{(k)}_{+}(x^*)} \bigg|  }
	\end{align}
\end{proposition}
In the proof of this proposition we will need the following lemma
\begin{lemma}\label{lemma}
	Under conditions of Proposition \ref{slope}:
	$$\footnote{$sign(x) = \begin{cases} -1, &x < 0\\ 0, &x = 0\\ 1, &x > 0 \end{cases}$}sign\left(\frac{\posder(x^*)}{\negder(x^*)} \right) \neq (-1)^k$$
	where we assume that ($sign(-\infty) = -1, sign(+\infty) = 1$)
\end{lemma}
\begin{proof}
	Suppose $k=2$, without loss of generality assume $x^* = 0$ and $u(x^*) = 0$. Then $u'(0) = 0$. Since $u$ is twicely differentiable to the left and to the right of zero, there should exist 
	\begin{align*}
		u''_{-}(0) = \lim_{\varepsilon \to 0^-} \frac{u'(\varepsilon)}{\varepsilon},\  u''_{+}(0) = \lim_{\varepsilon \to 0^+} \frac{u'(\varepsilon)}{\varepsilon}
		\end{align*}
	By assumption, $u$ is strictly increasing and differentiable in a neighborhood of $x^*$ which means that $u'(x) \ge 0$. Hence \begin{align*}
		u''_{-}(0) = \lim_{\varepsilon \to 0^-} \frac{u'(\varepsilon)}{\varepsilon} \le 0\\
		u''_{+}(0) = \lim_{\varepsilon \to 0^+} \frac{u'(\varepsilon)}{\varepsilon} \ge 0
	\end{align*}
and consequently $sign\left(\frac{u''_{+}(x^*)}{u''_{-}(x^*)} \right) \neq 1$. 

Suppose $k = 3$ then $u'(0) = u''(0) = 0$ and as we saw for the case of $k=1$, 
 \begin{align*}
	u''_{-}(0) \le 0,\ u''_{+}(0) \ge 0
\end{align*}
then \begin{align*}
	u^{(3)}_{-}(0) = \lim_{\varepsilon \to 0^-} \frac{u''(\varepsilon)}{\varepsilon} \ge 0\\
	u^{(3)}_{+}(0) = \lim_{\varepsilon \to 0^+} \frac{u''(\varepsilon)}{\varepsilon} \ge 0
\end{align*}
meaning that $sign\left(\frac{u^{(3)}_{+}(x^*)}{u^{(3)}_{-}(x^*)} \right) \neq -1$. Proceeding in the same way, we can prove the result for an arbitrary $k$.
\end{proof}
\begin{proof} of Proposition \ref{slope}
	
	
	
	Consider small $\epsilon > 0$, then
	\begin{align*}
		u(x^* + \epsilon) = u(x^*) + \frac{u^{(k)}_{+}(x^*) \epsilon^k}{k!} + o(\epsilon^k)\\
		u(x^* + \epsilon)= u(x^*)+\epsilon^k\left( \frac{u^{(k)}_{+}(x^*)}{k!} + o(1) \right)
	\end{align*}
where $o(\cdot)$ is defined as $\epsilon \to 0$.
Similarly, for small $\omega <0$
\begin{align*}
	u(x^* + \omega) = u(x^*) + \frac{u^{(k)}_{-}(x^*) \omega^k}{k!} + o(\omega^k)\\
	u(x^* + \omega) = u(x^*) + \omega^k\left( \frac{u^{(k)}_{-}(x^*)}{k!} + o(1) \right)
\end{align*}
where $o(\cdot)$ is defined as $\omega \to 0$.
Consider $x_1 = x^*+\epsilon$, then since $u(x)$ is strictly increasing implies that $x_2 = x^* + \omega(\epsilon)$. Then,
\begin{align*}
	\frac{dx_2}{dx_1}\bigg|_{x_1=x^*+0} = \lim_{\epsilon \to 0^+} \frac{\omega(\epsilon)}{\epsilon}
\end{align*}
and \eqref{ind} implies:
\begin{align*}
		p\epsilon^k\left( \frac{u^{(k)}_{+}(x^*)}{k!} + o(1) \right) + (1-p)\omega^k(\epsilon)\left( \frac{u^{(k)}_{-}(x^*)}{k!} + o(1) \right) = 0\\
		\left(\frac{\omega(\epsilon)}{\epsilon}\right)^k = -\frac{p}{1-p} \frac{\left( \frac{u^{(k)}_{+}(x^*)}{k!} + o(1) \right)}{\left( \frac{u^{(k)}_{-}(x^*)}{k!} + o(1) \right)}
\end{align*}
By Lemma \ref{lemma} $sign\left(\frac{\posder(x^*)}{\negder(x^*)} \right) \neq (-1)^k$ then 
\begin{align*}
		\frac{dx_2}{dx_1}\bigg|_{x_1=x^*+0} = \lim_{\epsilon \to 0^+}\frac{\omega(\epsilon)}{\epsilon} = -\sqrt[k]{\frac{p}{1-p} \bigg|\frac{\posder(x^*)}{\negder(x^*)} \bigg| }
\end{align*}
$\frac{dx_2}{dx_1}\bigg|_{x_1=x^*-0}$ can be found in exactly the same way.
\end{proof}
In contrast to the result above it is known that in case of differentiable Bernoulli utility, the slope of an expected-utility maximizer's indifference curve at certainty points where $u'(x) \neq 0$ is equal to $-\frac{p}{1-p}$. If this individual is offered to buy insurance which would cost $\gamma$ for every insured unit and pay $\$\ 1$ in case of the bad event occurs, then the individual's budget constraint would have a slope $-\frac{\gamma}{1-\gamma}$. This in particular explains why such an expected-utility maximizer never buys full insurance unless it is actuarially fair (i.e. $\gamma = p$). At the same time, as we see from Proposition \ref{slope} an individual with $k$ times differentiable Bernoulli utility with the first $k-1$ derivatives equal to zero at some $x$ has slope of the indifference curve at $(x, x)$ given by $-\sqrt[k]{\frac{p}{1-p}}$. So depending on $p$ there may exist a range of positive loading $\gamma > p$ for which the expected utility maximizer would find it optimal to buy full insurance. In terms of Proposition \ref{LRA}, this range corresponds to the range of lotteries with positive expectation satisfying condition \eqref{condition}. Section \ref{Examples} illustrates Propositions \ref{LRA} and \ref{slope} by concrete examples.


But before going to examples, let's consider another class of Bernoulli utility functions that have zero derivative. In particular, consider strictly increasing and continuous utility functions which have first derivative equals zero not at a particular point but almost everywhere.

\section{Strictly singular Bernoulli utility function}\label{Bsingular}
\begin{definition}
	A continuous, non-constant function $f:\mathbb{R} \to \mathbb{R}$ is called (strictly) \textbf{singular} if it is (strictly) monotone and has zero derivative almost everywhere i.e. $$f'(x) = 0 \text{ a.e.}$$.
\end{definition}
For examples of such functions see \cite{salem1943some} or \cite{berg2000rham}.
From now on, unless otherwise stated I will consider increasing singular functions defined on the interval $[a, b]$ for some $a, b \in \mathbb{R}, a<b$. For the result below it is useful to have the following proposition.
\begin{proposition}\label{inverse}
	If $f$ is a strictly singular function, then the inverse $g = f^{-1}$ is 
	also strictly singular.
\end{proposition}
\begin{proof}
	See \cite{berg2000rham}
\end{proof}
Suppose an individual has a strictly singular Bernoulli utility function $u: [a, b] \to [u(a), u(b)]$. Denote $$E = \{ y \in [u(a), u(b)]: \text{ either } \nexists\ (u^{-1})'(y) \text{ or }\exists\ (u^{-1})'(y) \neq 0 \}.$$ By Proposition \ref{inverse}, Lebesgue measure of $E$ equals zero. For the next propositions we will be interested in a set $D = u^{-1}(E) = \{x\in[a, b]: u(x) \in E\}$, the preimage of set $E$ under the mapping $u$.
\begin{proposition}\label{pi}
	Suppose $u(x)$ is strictly singular. Then $\forall\ x \in [a, b]\setminus D: \frac{\partial \pi (t, x)}{\partial t} \bigg|_{t=0} = 0$. In particular, if $|D| = 0$, $\frac{\partial \pi (t, x)}{\partial t} \bigg|_{t=0} = 0\ \text{a.e.}$
\end{proposition}
\begin{proof}
	By definition
	\begin{align*}
		\pi(t, x) &= x - u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right)\\
		\frac{\partial \pi(t, x)}{\partial t} &= -\left(u^{-1}\left( \int u(x + t \varepsilon) dF(\varepsilon) \right) \right)' \int u'(x+t \varepsilon)\varepsilon dF(\varepsilon)\\
		\frac{\partial \pi(t, x)}{\partial t} \bigg|_{t=0} &= -\left(u^{-1}\left( u(x) \right) \right)' \int u'(x)\varepsilon dF(\varepsilon)
	\end{align*}
Since $\forall\ x \in [a, b]\setminus D,\ u(x) \notin E\ \to\ (u^{-1}(u(x))) = 0$.
 Thus, $$\frac{\partial \pi(t, x)}{\partial t}\bigg|_{t = 0} = 0$$
\end{proof}
\begin{corollary}
	If $u$ is strictly singular and a preimage of any null set has Lebesgue measure zero, then $$\frac{\partial \pi (t, x)}{\partial t} \bigg|_{t=0} = 0\ \text{a.e.}$$
\end{corollary}
\begin{proof}
If a preimage of any null set has Lebesgue measure zero, then $|D| = 0$.
\end{proof}
As we can see, an individual with a strictly singular Bernoulli utility function under some conditions has an attitude toward risk of order 2. This stands in contrast to the case considered in Section \ref{order} where an individual has Bernoulli utility with zero derivatives up to some order at a particular point. At the same time, as we know, the same result holds in case an individual has a utility function with $u'(x) > 0$. However, this is more of a coincidence rather than something general. The next proposition shows that characteristics of indifference curves of an individual with strictly singular Bernoulli utility function differ from that of an individual with $u'(x) > 0$. In particular, the slope (derivative) of the indifference curve does not equal $-\frac{p}{1-p}$ almost everywhere.
\begin{proposition}\label{singular}
	Suppose $u(x)$ is strictly singular. Consider an indifference curve $x_2(x_1)$ implicitly given by $$\{ (x_1, x_2):pu(x_1)+(1-p)u(x_2) = u(x^*) \}$$ for some $x^*$ between $x_1$ and $x_2$. Denote $F(x^*) = \{ x_1 \in [a, b]: \frac{u(x^*) - p u(x_1)}{1-p} \in E\}$. Then $$\forall\ x_1 \in [a, b] \setminus F(x^*):  \frac{dx_2(x_1)}{dx_1} = 0$$ In particular, if $|F(x^*)| = 0$ then $$\frac{dx_2(x_1)}{dx_1} = 0 \text{ a.e.}$$
\end{proposition}
\begin{proof}
	Since $u(x)$ is strictly increasing and continuous, there exists strictly increasing and continuous $u^{-1}$ which is also strictly singular by Proposition \ref{inverse}. \begin{align*}
		x_2(x_1) = u^{-1} \left( \frac{u(x^*) - pu(x_1)}{1-p} \right)
	\end{align*}
By the chain rule then \begin{align*}
	\frac{dx_2(x_1)}{dx_1} = -(u^{-1})'\left( \frac{u(x^*) - pu(x_1)}{1-p} \right)\frac{p}{1-p}u'(x_1)
\end{align*}
Since $\forall\ x_1 \in [a, b] \setminus F(x^*):\ \frac{u(x^*) - pu(x_1)}{1-p} \notin E\to (u^{-1})'\left( \frac{u(x^*) - pu(x_1)}{1-p} \right) = 0$. Hence, $$\frac{dx_2(x_1)}{dx_1} = 0$$
If Lebesgue measure of $F(x^*)$ is zero then $$\frac{dx_2(x_1)}{dx_1} = 0 \text{ a.e.}$$
\end{proof}
\begin{corollary}
	If $u$ is strictly singular and a preimage of any null set has Lebesgue measure zero, then $$\frac{dx_2(x_1)}{dx_1} = 0 \text{ a.e.}$$
\end{corollary}
\begin{proof}
If a preimage of any null set has Lebesgue measure zero, then $|D| = 0$ but since $\frac{u(x^*) - pu(x_1)}{1-p}$ is simply an affine transformation of $u(x_1)$, clearly $|F(x^*)| = 0$ as well.
\end{proof}
Talking about optimal insurance, it seems that from the proposition above it follows that similar to the case with zero derivatives at a particular point, an individual with a strictly singular Bernoulli utility function must admit local risk aversion and prefer full insurance. This, however, is not completely true. The reason is that for singular functions the derivative can hardly be interpreted in a usual manner (as a slope). Thus, even though mathematically the derivative of the function which defines indifference curves indeed may be equal to zero, for the typical singular function, indifference curves will be ``very irregular'', meaning that it is impossible to say in general which choice of insurance (even locally) would be optimal for such an individual.

\section{Examples}\label{Examples}
Without loss of generality, for simplicity restrict attention to $x^* = 0$. In all examples I assume that there are two states of the world: the first occurs with a given probability $p$ and the second with a probability $1-p$, and in state $i\in\{1, 2\}$ the individual receives $x_i$.
\subsection{Example 1}
Consider $u(x) = x^3$, this is what first comes to mind when we are talking about a strictly increasing function with zero first derivative at some point. First of all, let us derive a risk premium $\pi(t)$ for the lottery $x+t\eps$ at $x = 0$:
\begin{align}
	-\pi(t, 0)^3 = \int t^3 \eps^3 dF(\eps)\\
	\pi(t, 0) = -t \sqrt[3]{\expect[\eps^3]}
\end{align}
Note that if $\expect[\eps^3] = 0$ then $\frac{\partial \pi(t, 0)}{\partial t}\bigg|_{t=0} = 0$ while if $\expect[\eps^3] \neq 0$, $\frac{\partial \pi(t, 0)}{\partial t}\bigg|_{t=0} \neq 0$ which demonstrates that in general, the individual's attitude toward risk is neither of order 1 nor of order 2.
So, if $\expect[\eps^3] \neq 0$, $\frac{\partial \pi(t, 0)}{\partial t}\bigg|_{t=0} = -\sqrt[3]{\expect[\eps^3]}$ exactly as Proposition \ref{derivative} claims.




The indifference curve corresponding to the utility level $u(0) = 0$ is given by:
\begin{align*}
	px_1^3 + (1-p)x_2^3 = 0\\
	x_2 = -\sqrt[3]{\frac{p}{1-p}} x_1
\end{align*}
As Proposition \ref{slope} states, $\frac{dx_2}{dx_1}\bigg|_{x_1=0} = -\sqrt[3]{\frac{p}{1-p}}$.
Consider the plot on the Fig \ref{fig1}. 
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{pic1}
	\caption{}\label{fig1}
\end{figure}

A blue line represents the indifference curve. Suppose that the individual initially faces the lottery $(x_1, p; x_2, 1-p)$ but in addition is offered to buy $0 \le c \le \frac{x_2}{\gamma}$ units of insurance each at a cost $\gamma$, which would pay him $\$ 1$ in (bad) state 1. A green line is the budget line which represents lotteries with insurance for all possible $c$. An orange line represents the line of constant, zero expectation, that is, each point on this line represents the lottery with zero expected payoff. Since the slope of this line is lower (in absolute value) than the slope of the green line, we have insurance with positive loading ($\gamma > p$). At the same, since the individual's utility increases as we are moving to the north-east, it is clear that the individual strictly prefers the lottery $(0, p; 0, 1-p)$ (that is, full insurance) to any other point on the green line. Clearly, the situation above is possible only ifÂ 
\begin{align}\label{negative moment}
	\frac{p}{1-p} < \frac{\gamma}{1-\gamma}< \sqrt[3]{\frac{p}{1-p}} \Rightarrow \begin{cases}
		\gamma(1-p) - (1-\gamma)p > 0\\
		-(1-\gamma)^3p+\gamma^3(1-p)<0
		\end{cases}
\end{align}
Note that the two conditions in \eqref{negative moment} are equivalent to 
\begin{align*}
	\begin{cases}
			\expect[\eps] >0\\
	\expect[\eps^3] < 0
	\end{cases}
\end{align*}
where $\eps = (-(1-\gamma), p; \gamma, (1-p))$.These two conditions are exactly what Proposition \ref{LRA} requires for the individual with positive $u'''(0)$ being locally risk averse.
\subsection{Example 2}
Consider $$u(x) = \begin{cases}
	x^2, &x \ge 0\\-x^2, &x < 0
\end{cases}$$
this example is interesting since $u(x)$ does not have a second derivative at $x^* = 0$. However, there exist finite left and right second derivatives, $u''_{+}(x^*) = 2, u''_{-}(x^*) = -2$. An indifference curve corresponding to the utility level 0 is given by:
\begin{align*}
	-px_1^2 + (1-p)x_2^2 = 0,\ \text{if } x_1 \le 0, x_2 \ge 0\\
	px_1^2-(1-p)x_2^2 = 0,\ \text{if } x_1 > 0, x_2 < 0\\
\end{align*}
$$	x_2 = -\sqrt{\frac{p}{1-p}}x_1$$
So, we have the same situation as in Ex.1. That is, $$\frac{p}{1-p}<\frac{\gamma}{1-\gamma}<\sqrt{\frac{p}{1-p}}$$ guarantees local risk aversion. This condition again implies that $$\begin{cases}
	\gamma(1-p)-p(1-\gamma)>0\\
	\gamma^2(1-p) - (1-\gamma)^2p < 0
\end{cases} \iff \begin{cases}
\expect[\eps]>0\\
\expect[ \eps^k | \eps\ge0]\prob(\eps\ge0) -\expect[ \eps^k | \eps<0]\prob(\eps<0) < 0
\end{cases}$$
where $\eps = (-(1-\gamma), p; \gamma, (1-p))$. Since $u''_{-}(0) = -2, u''_{+}(0)=2$, the second condition above is equivalent to \eqref{condition} requirement in Proposition \ref{LRA} for the individual being locally risk averse.
\subsection{Example 3}
Consider $$u(x) = \begin{cases}
	x^3, &x \ge 0\\-x^2, &x < 0
\end{cases}$$
In this example, as in example 2, $u(x)$ is not differentiable at $x^*=0$. What is more interesting, here only left second derivative is non-zero at $x^*=0$.
An indifference curve corresponding to the utility level 0 is given by:
\begin{align*}
	-px_1^2 + (1-p)x_2^3 = 0,\ \text{if } x_1 \le 0, x_2 \ge 0\\
	px_1^3-(1-p)x_2^2 = 0,\ \text{if } x_1 > 0, x_2 < 0\\
\end{align*}
\begin{align}	\label{ic}
	x_2 = \begin{cases} 
	\sqrt[3]{\frac{p}{1-p}}\ |x_1|^{\frac{2}{3}}, &x_1\le0\\
	-\sqrt{\frac{p}{1-p}}\ x_1^{\frac{3}{2}}, &x_1>0
	\end{cases}
\end{align}
Here, $k=2$, $u^{''}_{+}(0) = 2, u^{''}_{-}(0) = 0$. From \eqref{ic} it follows
\begin{align*}
	\frac{dx_2}{dx_1}\bigg|_{x_1=0^-} = +\infty,\  \frac{dx_2}{dx_1}\bigg|_{x_1=0^+} = 0
\end{align*}
which corresponds to what Proposition \ref{slope} claims. Fig. \ref{fig2} demonstrates the point. Here, as in example 1, an individual strictly prefers full insurance with positive loading to his initial lottery $(x_1, x_2)$. At the same time, in contrast to example 1, here it is the case not for all $(x_1, x_2)$ which lies on the insurance budget constraint (green line) but only down to the point $(\bar{x}_1, \bar{x_2})$. That is, in terms of Proposition \ref{LRA}, an individual prefers a certain outcome to the small positive risk only for $t$ small enough. Note also, that condition \eqref{condition} of the Proposition \ref{LRA} holds, since $u''_{-}(0) = -2,\ \expect[\eps^2|\eps\ge0] > 0$, and $u''_{+}(0) = 0$, where $\eps = (-(1-\gamma), p; \gamma, (1-p))$. 



\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{pic2}
	\caption{}\label{fig2}
\end{figure}
It is worth mentioning also that in this example, since the leftÂ slope of the indifference curve at zero is infinite, even for very large positive loading $\gamma >> p$, there exists small enough $t$ such that the individual would prefer full insurance to a lottery with small positive expectation.


Finally, note that, if instead we considered $u(x) = \begin{cases}
	x^2, & x\ge0\\
	x^3, & x <0
\end{cases}$, it would be $\frac{dx_2}{dx_1}\bigg|_{x_1=0^-} = 0$. That means that the indifference curve would lie below the insurance budget constraint in the left neighborhood of $x^*=0$. Thus, in this case, no matter how small $t$ was, the individual would strictly prefer small positive risk to full insurance. So, Proposition \ref{LRA} ``does not work'' here. The reason for that is a violation of condition \eqref{condition} ($u''_{+}(0)\ Â \expect[\eps^2|\eps\ge0]\ \prob(\eps\ge0)>0$).
\section{Conclusion}
	\newpage
	\bibliography{lib}{}
	%\bibliographystyle{unsrt}
	%\bibliographystyle{apalike}
	\bibliographystyle{abbrvnat}
	\end{document}